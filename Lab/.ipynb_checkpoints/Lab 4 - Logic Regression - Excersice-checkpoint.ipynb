{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training dataset\n",
    "train = pd.read_csv('train_clean.csv',index_col = 'PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define attributes and target variable\n",
    "features = ['Pclass','Age','SibSp','Parch','Fare','Sex_male','Embarked_Q','Embarked_S']\n",
    "target = ['Survived']\n",
    "X = train [features]\n",
    "y = train [target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize attributes\n",
    "zscore_scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_transform = pd.DataFrame(zscore_scaler.transform(X), columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass   Age  SibSp  Parch     Fare  Sex_male  Embarked_Q  \\\n",
       "PassengerId                                                              \n",
       "1                 3  22.0      1      0   7.2500         1           0   \n",
       "2                 1  38.0      1      0  71.2833         0           0   \n",
       "3                 3  26.0      0      0   7.9250         0           0   \n",
       "4                 1  35.0      1      0  53.1000         0           0   \n",
       "5                 3  35.0      0      0   8.0500         1           0   \n",
       "\n",
       "             Embarked_S  \n",
       "PassengerId              \n",
       "1                     1  \n",
       "2                     0  \n",
       "3                     1  \n",
       "4                     1  \n",
       "5                     1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.592481</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.619306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.638789</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>-1.614710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.284663</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.619306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.619306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.827377</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.619306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass       Age     SibSp     Parch      Fare  Sex_male  Embarked_Q  \\\n",
       "0  0.827377 -0.592481  0.432793 -0.473674 -0.502445  0.737695   -0.307562   \n",
       "1 -1.566107  0.638789  0.432793 -0.473674  0.786845 -1.355574   -0.307562   \n",
       "2  0.827377 -0.284663 -0.474545 -0.473674 -0.488854 -1.355574   -0.307562   \n",
       "3 -1.566107  0.407926  0.432793 -0.473674  0.420730 -1.355574   -0.307562   \n",
       "4  0.827377  0.407926 -0.474545 -0.473674 -0.486337  0.737695   -0.307562   \n",
       "\n",
       "   Embarked_S  \n",
       "0    0.619306  \n",
       "1   -1.614710  \n",
       "2    0.619306  \n",
       "3    0.619306  \n",
       "4    0.619306  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Logistic Regression from sklearn\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model to be logistic regression\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# penalty='l1' means L1 regularization (recall LASSO regression); default is penality='L2' (L2 regularization). C=1.0 is inverse of regularization strength; must be a positive float.\n",
    "# 'saga' is the algorithm to use in the optimization problem (finding the optimal coefficient values)\n",
    "lr = LogisticRegression(penalty='l1', C=1.0, random_state=0, solver='saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cross validation and other evaluation tool \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change target column to array\n",
    "yact = y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cv = cross_val_score(lr, X_transform, yact, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7946192259675405"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy from cross validation\n",
    "score_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict value of target based on cross validation\n",
    "pred_y = cross_val_predict(lr, X_transform, yact, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[469  80]\n",
      " [103 239]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print(confusion_matrix(y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       549\n",
      "           1       0.75      0.70      0.72       342\n",
      "\n",
      "    accuracy                           0.79       891\n",
      "   macro avg       0.78      0.78      0.78       891\n",
      "weighted avg       0.79      0.79      0.79       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yact, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold and ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probablities for each prediction\n",
    "proba_y = cross_val_predict(lr, X_transform, yact, cv=10, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'proba_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-069e8d20f9f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mproba_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'proba_y' is not defined"
     ]
    }
   ],
   "source": [
    "proba_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90383872, 0.07386228, 0.38423029, 0.09674271, 0.9263234 ,\n",
       "       0.87998415, 0.72065533, 0.88404409, 0.47767433, 0.09465835,\n",
       "       0.2759629 , 0.18518448, 0.87460769, 0.97647098, 0.28033079,\n",
       "       0.38630605, 0.86975736, 0.76866383, 0.4793171 , 0.33366429,\n",
       "       0.79841002, 0.79733545, 0.22548364, 0.49186857, 0.40540937,\n",
       "       0.73811437, 0.87634869, 0.51183712, 0.34158843, 0.91082117,\n",
       "       0.52280178, 0.04549201, 0.34166134, 0.93295403, 0.42580493,\n",
       "       0.66679593, 0.87634755, 0.87885256, 0.40716438, 0.24961236,\n",
       "       0.57251918, 0.20463991, 0.8761662 , 0.08564855, 0.25417042,\n",
       "       0.91078974, 0.89955949, 0.34166134, 0.9135275 , 0.35596383,\n",
       "       0.91673026, 0.87891932, 0.10809036, 0.21559447, 0.76185023,\n",
       "       0.50855264, 0.14373489, 0.87115231, 0.13151654, 0.9493578 ,\n",
       "       0.83968167, 0.05905482, 0.67537528, 0.90621341, 0.422296  ,\n",
       "       0.91144604, 0.18688728, 0.87020536, 0.59791633, 0.93162545,\n",
       "       0.78540292, 0.6171449 , 0.66979926, 0.88211197, 0.90822426,\n",
       "       0.89470566, 0.91082117, 0.91078974, 0.59331263, 0.4192326 ,\n",
       "       0.88272642, 0.90823032, 0.34350483, 0.48459649, 0.13453399,\n",
       "       0.67413534, 0.92153869, 0.91078974, 0.09402649, 0.89084979,\n",
       "       0.9085331 , 0.87466156, 0.69589613, 0.93792646, 0.96665711,\n",
       "       0.91056841, 0.73849307, 0.33333291, 0.22479656, 0.84190437,\n",
       "       0.40472018, 0.91059757, 0.43568889, 0.91959556, 0.96145043,\n",
       "       0.90554226, 0.34642127, 0.91062041, 0.93193951, 0.40901243,\n",
       "       0.66383008, 0.24921872, 0.88555594, 0.41148337, 0.20893738,\n",
       "       0.88192332, 0.96932343, 0.81844323, 0.25250866, 0.49918064,\n",
       "       0.80476835, 0.91056841, 0.74486542, 0.21170152, 0.71458105,\n",
       "       0.81180375, 0.88064896, 0.89278764, 0.36986733, 0.9462698 ,\n",
       "       0.86994827, 0.87837749, 0.64424255, 0.24012477, 0.74348291,\n",
       "       0.61063347, 0.05672226, 0.65453568, 0.86170522, 0.32282439,\n",
       "       0.31272457, 0.35448309, 0.44294071, 0.83472622, 0.69383117,\n",
       "       0.76120298, 0.90246906, 0.40220658, 0.82302323, 0.84160019,\n",
       "       0.87996795, 0.07087847, 0.96232551, 0.94178874, 0.91070781,\n",
       "       0.57679223, 0.24306517, 0.91143804, 0.91045248, 0.99193534,\n",
       "       0.94574267, 0.25851139, 0.89929033, 0.86604837, 0.92698181,\n",
       "       0.83845335, 0.07289749, 0.66318063, 0.51352021, 0.90797557,\n",
       "       0.77800814, 0.9197325 , 0.27058014, 0.88810239, 0.64819071,\n",
       "       0.91734153, 0.971365  , 0.08181464, 0.77670174, 0.93456756,\n",
       "       0.92395561, 0.6856112 , 0.95967705, 0.6963656 , 0.23483988,\n",
       "       0.50701304, 0.41387793, 0.66110614, 0.943527  , 0.93404337,\n",
       "       0.20874218, 0.69465108, 0.40398027, 0.64882382, 0.07212589,\n",
       "       0.08855971, 0.87821728, 0.95212774, 0.34352447, 0.14373163,\n",
       "       0.91213569, 0.99501802, 0.92922473, 0.92856874, 0.87605266,\n",
       "       0.20495192, 0.94427112, 0.85811414, 0.20542771, 0.49829405,\n",
       "       0.89918915, 0.2028307 , 0.89195157, 0.77670174, 0.91036062,\n",
       "       0.0521335 , 0.37836629, 0.88462628, 0.04053558, 0.77717037,\n",
       "       0.86742385, 0.75597725, 0.96192395, 0.91738342, 0.65646688,\n",
       "       0.89173247, 0.69522434, 0.88624367, 0.68640278, 0.67359386,\n",
       "       0.09442712, 0.91532512, 0.91414976, 0.55371466, 0.7345157 ,\n",
       "       0.4032604 , 0.89237843, 0.09980653, 0.69522434, 0.79626801,\n",
       "       0.37519067, 0.37991146, 0.77041442, 0.8919646 , 0.87724739,\n",
       "       0.68777944, 0.36042388, 0.17234808, 0.68093727, 0.92423033,\n",
       "       0.91743635, 0.49105935, 0.76034872, 0.93257472, 0.5245871 ,\n",
       "       0.340052  , 0.0371064 , 0.05735667, 0.02874781, 0.33480733,\n",
       "       0.88184693, 0.94969707, 0.75652198, 0.58552605, 0.33809976,\n",
       "       0.79249529, 0.96125588, 0.92880347, 0.15677098, 0.06540311,\n",
       "       0.48039034, 0.9033027 , 0.26368834, 0.46573718, 0.30492965,\n",
       "       0.2361347 , 0.54014673, 0.75237435, 0.93271515, 0.56216601,\n",
       "       0.96618912, 0.89989908, 0.85043501, 0.88018348, 0.48168779,\n",
       "       0.88041143, 0.91812906, 0.87738241, 0.84680268, 0.27596183,\n",
       "       0.04970294, 0.03713349, 0.72080853, 0.34550247, 0.88533336,\n",
       "       0.3859998 , 0.83706144, 0.03008671, 0.48052008, 0.07235358,\n",
       "       0.33809976, 0.93823097, 0.86552824, 0.13774737, 0.9055541 ,\n",
       "       0.30314089, 0.037964  , 0.03389574, 0.74498807, 0.04050866,\n",
       "       0.03166581, 0.04717472, 0.21022286, 0.89989518, 0.8812689 ,\n",
       "       0.36313795, 0.18985813, 0.88298008, 0.06023419, 0.0793958 ,\n",
       "       0.87745461, 0.89641669, 0.13911213, 0.18560476, 0.99454547,\n",
       "       0.04659666, 0.96931507, 0.20679112, 0.50745862, 0.02540364,\n",
       "       0.50969447, 0.62832749, 0.54021476, 0.92098818, 0.07560225,\n",
       "       0.90556781, 0.55509097, 0.05587326, 0.94492621, 0.62216706,\n",
       "       0.60956324, 0.11653984, 0.73753257, 0.7148565 , 0.79206763,\n",
       "       0.14175938, 0.2328564 , 0.48342483, 0.83910423, 0.93864163,\n",
       "       0.88127106, 0.47935257, 0.84914092, 0.919458  , 0.86672295,\n",
       "       0.89974487, 0.05581948, 0.21954588, 0.32193008, 0.32193008,\n",
       "       0.96260244, 0.73087199, 0.45427948, 0.92283559, 0.90101387,\n",
       "       0.90732403, 0.16909126, 0.2986941 , 0.32200396, 0.03481923,\n",
       "       0.43229295, 0.89214802, 0.86296979, 0.28682091, 0.37903218,\n",
       "       0.05626287, 0.33118172, 0.32005536, 0.80730529, 0.86305496,\n",
       "       0.04661573, 0.13412329, 0.91368335, 0.11193888, 0.90616535,\n",
       "       0.64326151, 0.93814223, 0.23177977, 0.87217802, 0.08224536,\n",
       "       0.64841439, 0.87221464, 0.94358054, 0.04035994, 0.37959658,\n",
       "       0.87659822, 0.41455884, 0.86196783, 0.72195553, 0.17994363,\n",
       "       0.93332351, 0.89279519, 0.39151034, 0.92326545, 0.31294546,\n",
       "       0.84215299, 0.95764514, 0.62737443, 0.87222071, 0.63660468,\n",
       "       0.90616535, 0.87243215, 0.06925169, 0.77714664, 0.94472107,\n",
       "       0.40189042, 0.28041214, 0.1467474 , 0.77330556, 0.25546916,\n",
       "       0.85931446, 0.828222  , 0.90376998, 0.47620179, 0.89615277,\n",
       "       0.9063091 , 0.2238866 , 0.12887097, 0.87217195, 0.91365753,\n",
       "       0.51811198, 0.47249278, 0.33530597, 0.85355525, 0.76537355,\n",
       "       0.05064057, 0.48994212, 0.30141839, 0.81931645, 0.78134813,\n",
       "       0.38288653, 0.8671855 , 0.9159815 , 0.17744602, 0.90846522,\n",
       "       0.3059274 , 0.11530942, 0.57749891, 0.26486157, 0.73251684,\n",
       "       0.86909637, 0.9272105 , 0.42338219, 0.66267233, 0.906131  ,\n",
       "       0.87005419, 0.82189671, 0.09066814, 0.34008174, 0.86444318,\n",
       "       0.70308011, 0.9215813 , 0.68734473, 0.8754868 , 0.90848046,\n",
       "       0.93238763, 0.78077153, 0.76422873, 0.86445177, 0.23367732,\n",
       "       0.90867522, 0.93208909, 0.29968836, 0.10918329, 0.32930507,\n",
       "       0.51727204, 0.84573436, 0.93052784, 0.88022735, 0.19788297,\n",
       "       0.96073181, 0.78077153, 0.95656244, 0.71066895, 0.43228063,\n",
       "       0.65050932, 0.09892527, 0.70650653, 0.90945762, 0.86850528,\n",
       "       0.92985057, 0.8761134 , 0.75494799, 0.79095269, 0.87585869,\n",
       "       0.87097916, 0.14235242, 0.90674792, 0.07081289, 0.8881794 ,\n",
       "       0.85753807, 0.23364072, 0.30025668, 0.46957424, 0.03665686,\n",
       "       0.35445124, 0.23726098, 0.53586498, 0.89899492, 0.88163894,\n",
       "       0.86119545, 0.90848046, 0.59671185, 0.14923785, 0.8882667 ,\n",
       "       0.69015901, 0.21569662, 0.85871138, 0.28216439, 0.91575205,\n",
       "       0.06066351, 0.88011142, 0.87334282, 0.08713721, 0.87334146,\n",
       "       0.90692251, 0.34008174, 0.3944874 , 0.93466393, 0.84885548,\n",
       "       0.10193774, 0.87334146, 0.86534612, 0.33349493, 0.40278134,\n",
       "       0.09415474, 0.67792664, 0.0462249 , 0.9068965 , 0.04290639,\n",
       "       0.09364471, 0.5327471 , 0.55207177, 0.83604086, 0.68146588,\n",
       "       0.82140893, 0.17380999, 0.71074274, 0.93984376, 0.67092135,\n",
       "       0.31587349, 0.75164886, 0.86456366, 0.83727257, 0.33160885,\n",
       "       0.80948458, 0.13819531, 0.34013633, 0.13091721, 0.53663897,\n",
       "       0.86458708, 0.93591845, 0.76457518, 0.90720061, 0.40086763,\n",
       "       0.93531151, 0.86573334, 0.42984457, 0.8741128 , 0.91451099,\n",
       "       0.92478951, 0.27001359, 0.60701452, 0.30409953, 0.85151794,\n",
       "       0.86378274, 0.21943245, 0.13264606, 0.39287428, 0.91449701,\n",
       "       0.21577031, 0.08981252, 0.89647478, 0.51397453, 0.87370001,\n",
       "       0.04776182, 0.87145604, 0.77962588, 0.87869853, 0.90720061,\n",
       "       0.92334205, 0.14525955, 0.95052485, 0.32341725, 0.86101338,\n",
       "       0.94564943, 0.18438159, 0.95485683, 0.87411397, 0.69985   ,\n",
       "       0.2699487 , 0.90723339, 0.53718604, 0.94462816, 0.51281267,\n",
       "       0.94444721, 0.90821462, 0.51848761, 0.13194655, 0.10326068,\n",
       "       0.61133597, 0.90741301, 0.36775877, 0.86458708, 0.92317654,\n",
       "       0.19743212, 0.94284697, 0.44047316, 0.13275982, 0.7516882 ,\n",
       "       0.89486714, 0.73128888, 0.86487547, 0.87454131, 0.87223857,\n",
       "       0.8010956 , 0.86797519, 0.05061138, 0.89438066, 0.86459202,\n",
       "       0.90345126, 0.95737589, 0.46316766, 0.56367745, 0.43627741,\n",
       "       0.17556403, 0.91895427, 0.83579646, 0.50590007, 0.93516011,\n",
       "       0.87359384, 0.03881068, 0.36700101, 0.91087827, 0.20978695,\n",
       "       0.69869965, 0.86896606, 0.69882942, 0.91160222, 0.3390003 ,\n",
       "       0.91159713, 0.12236583, 0.87806896, 0.29370762, 0.20424791,\n",
       "       0.8423623 , 0.91159713, 0.38793533, 0.72545973, 0.70927121,\n",
       "       0.83935345, 0.91334932, 0.70586805, 0.93043182, 0.90637077,\n",
       "       0.88142468, 0.74158591, 0.91159891, 0.94695246, 0.09700405,\n",
       "       0.32554234, 0.63353509, 0.94840646, 0.78613574, 0.77738481,\n",
       "       0.86419868, 0.89271224, 0.2943247 , 0.60652203, 0.4800707 ,\n",
       "       0.29369593, 0.4103906 , 0.87356615, 0.96594901, 0.943826  ,\n",
       "       0.7240473 , 0.95340993, 0.86891868, 0.86419823, 0.03869121,\n",
       "       0.63332277, 0.1341151 , 0.91087827, 0.85022068, 0.80401887,\n",
       "       0.89735336, 0.94898728, 0.29371126, 0.70412891, 0.944845  ,\n",
       "       0.04113198, 0.59390962, 0.21625884, 0.83934858, 0.92537193,\n",
       "       0.83609989, 0.28355885, 0.62648056, 0.049206  , 0.90474667,\n",
       "       0.0374935 , 0.54025985, 0.733771  , 0.9092208 , 0.89736178,\n",
       "       0.86897118, 0.05327015, 0.17131679, 0.86363984, 0.92197655,\n",
       "       0.09673742, 0.89533985, 0.79108116, 0.87111196, 0.56280516,\n",
       "       0.87230542, 0.35955504, 0.30210804, 0.78498004, 0.4369391 ,\n",
       "       0.05982956, 0.75976103, 0.76600389, 0.71771121, 0.71771121,\n",
       "       0.9023377 , 0.71495296, 0.36523079, 0.90664233, 0.90664233,\n",
       "       0.51719834, 0.63606241, 0.06411948, 0.91373057, 0.91055196,\n",
       "       0.87168605, 0.8991178 , 0.18699637, 0.49071823, 0.86600343,\n",
       "       0.11929968, 0.82228383, 0.9161832 , 0.88398597, 0.42108529,\n",
       "       0.63256691, 0.90130967, 0.67988775, 0.91900674, 0.07501469,\n",
       "       0.90620427, 0.93602357, 0.81552305, 0.13130593, 0.85536926,\n",
       "       0.17449697, 0.40733322, 0.30825526, 0.89145395, 0.91343065,\n",
       "       0.88752306, 0.9495991 , 0.3798932 , 0.86265521, 0.51302716,\n",
       "       0.86410249, 0.86044234, 0.21739667, 0.86044352, 0.1064735 ,\n",
       "       0.19412472, 0.05903026, 0.51087453, 0.94274844, 0.89127322,\n",
       "       0.89125807, 0.30868612, 0.91173339, 0.85375696, 0.54594464,\n",
       "       0.86044234, 0.66139015, 0.90076773, 0.4090153 , 0.89120911,\n",
       "       0.81943265, 0.13177498, 0.40429284, 0.8639406 , 0.50877481,\n",
       "       0.79108116, 0.24878919, 0.44797231, 0.73385198, 0.89921654,\n",
       "       0.91056151, 0.60565221, 0.2987498 , 0.82389316, 0.09608336,\n",
       "       0.89579049, 0.93051598, 0.80264365, 0.49564571, 0.90992422,\n",
       "       0.5398781 , 0.33763015, 0.78210798, 0.94070155, 0.92916667,\n",
       "       0.17999921, 0.89899412, 0.61254553, 0.39283159, 0.92002304,\n",
       "       0.87727554, 0.90145982, 0.50679464, 0.87715033, 0.13798373,\n",
       "       0.26603853, 0.63168472, 0.87723185, 0.88529828, 0.86568563,\n",
       "       0.09220908, 0.87767275, 0.90753834, 0.90856186, 0.44968039,\n",
       "       0.87388172, 0.6726968 , 0.0516417 , 0.89473766, 0.86139098,\n",
       "       0.93857373, 0.98998789, 0.89622034, 0.77208815, 0.06116499,\n",
       "       0.93264836, 0.97968074, 0.24414024, 0.04717982, 0.32319547,\n",
       "       0.31991327, 0.13336924, 0.70815015, 0.33873176, 0.87723185,\n",
       "       0.9619556 , 0.76370997, 0.12588941, 0.86721294, 0.73187185,\n",
       "       0.25604108, 0.16100153, 0.53325364, 0.9073614 , 0.84970377,\n",
       "       0.89578937, 0.16294696, 0.56737689, 0.94804481, 0.16388379,\n",
       "       0.21774064, 0.87357381, 0.86987417, 0.90755714, 0.124458  ,\n",
       "       0.16870808, 0.91703567, 0.32881283, 0.75977665, 0.89250612,\n",
       "       0.51456467, 0.7524836 , 0.04808908, 0.50538202, 0.41695825,\n",
       "       0.88578243])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilities of being '0' for all instances at default threshold of 0.5\n",
    "proba_y_0 = proba_y[:,0]\n",
    "proba_y_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower threshold for '0' to be 0.4\n",
    "proba_y_0_lt= [0 if i >= 0.4 else 1 for i in proba_y_0]\n",
    "proba_y_0_lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[503  46]\n",
      " [124 218]]\n",
      "Accuracy: 0.8092031425364759\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\", '\\n',confusion_matrix(y, proba_y_0_lt))\n",
    "print(\"Accuracy:\",accuracy_score(y, proba_y_0_lt, normalize=True, sample_weight=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tpr and fpr based on different thresholds\n",
    "fpr, tpr, thresholds = metrics.roc_curve(yact,proba_y_0,pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8501209003078432"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bec1037250>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', random_state=0, solver='saga')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model using training dataset\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit\n",
    "lr.fit(X_transform, yact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.64560104])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the intercept of the trained model (Theta_0)\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.910376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.498802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.343474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.065449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.087607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_male</th>\n",
       "      <td>-1.285060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>-0.179448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coefficient\n",
       "Pclass        -0.910376\n",
       "Age           -0.498802\n",
       "SibSp         -0.343474\n",
       "Parch         -0.065449\n",
       "Fare           0.087607\n",
       "Sex_male      -1.285060\n",
       "Embarked_Q     0.000000\n",
       "Embarked_S    -0.179448"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the coefficients of independent attributes\n",
    "# the reason that we use the function .flatten() here is to convert the 8X1 array to 1X8 array\n",
    "coeff_df = pd.DataFrame(lr.coef_.flatten(), X.columns, columns=['Coefficient'])  \n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
